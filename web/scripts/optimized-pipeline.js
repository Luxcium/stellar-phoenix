#!/usr/bin/env node

/**
 * Script de d√©monstration du pipeline optimis√©
 * 
 * Ce script illustre l'utilisation combin√©e des optimisations:
 * 1. RAM Disk pour les op√©rations temporaires
 * 2. Streaming des fichiers par chunks
 * 3. Gestion intelligente des workers
 * 4. Extraction acc√©l√©r√©e avec libarchive (via processus externe)
 */

import path from 'path';
import fs from 'fs';
import { execSync } from 'child_process';
import { processFileStream, batchProcessFiles } from './file-streamer.js';
import os from 'os';

// Configuration
const DEFAULT_RAMDISK_PATH = process.env.RAMDISK_PATH || '/tmp/ramdisk';
const CONCURRENCY = Math.max(1, os.cpus().length - 1);

/**
 * V√©rifie si un RAM Disk est disponible
 */
function checkRamDisk() {
  if (!fs.existsSync(DEFAULT_RAMDISK_PATH)) {
    console.warn(`‚ö†Ô∏è AVERTISSEMENT: RAM Disk non d√©tect√© √† ${DEFAULT_RAMDISK_PATH}`);
    console.warn('Pour maximiser les performances, ex√©cutez d\'abord: sudo scripts/setup_ramdisk.sh');
    return false;
  }
  
  console.log(`‚úÖ RAM Disk d√©tect√© √† ${DEFAULT_RAMDISK_PATH}`);
  return true;
}

/**
 * V√©rifie si les d√©pendances sont install√©es
 */
function checkDependencies() {
  try {
    // V√©rifier si Python est disponible
    execSync('which python3', { stdio: 'ignore' });
    console.log('‚úÖ Python 3 d√©tect√©');
    
    // V√©rifier si libarchive est install√©
    execSync('python3 -c "import libarchive"', { stdio: 'ignore' });
    console.log('‚úÖ Python libarchive-c d√©tect√©');
    
    // V√©rifier si pigz (parallel gzip) est install√©
    try {
      execSync('which pigz', { stdio: 'ignore' });
      console.log('‚úÖ pigz d√©tect√© (compression parall√®le disponible)');
    } catch {
      console.warn('‚ö†Ô∏è pigz non d√©tect√©, utilisation de gzip standard (moins efficace)');
    }
    
    return true;
  } catch (err) {
    console.error('‚ùå D√©pendances manquantes:', err.message);
    console.error('Veuillez installer les d√©pendances requises:');
    console.error('- Python 3: https://www.python.org/downloads/');
    console.error('- libarchive-c: pip install libarchive-c');
    console.error('- pigz (optionnel): https://zlib.net/pigz/');
    return false;
  }
}

/**
 * Extrait une archive avec libarchive (via le script Python)
 * @param {string} archivePath - Chemin de l'archive √† extraire
 * @param {string} destination - Dossier de destination
 */
function extractWithLibarchive(archivePath, destination) {
  console.log(`üì¶ Extraction de ${path.basename(archivePath)} vers ${destination}...`);
  
  try {
    const cmd = `python3 ${path.join(__dirname, 'extract_with_libarchive.py')} "${archivePath}" "${destination}"`;
    execSync(cmd, { stdio: 'inherit' });
    console.log(`‚úÖ Extraction termin√©e pour ${path.basename(archivePath)}`);
    return true;
  } catch (err) {
    console.error(`‚ùå Erreur lors de l'extraction de ${path.basename(archivePath)}:`, err.message);
    return false;
  }
}

/**
 * Compresse un fichier ou dossier en utilisant pigz si disponible
 * @param {string} inputPath - Chemin du fichier/dossier √† compresser
 * @param {string} outputPath - Chemin du fichier de sortie
 */
function compressWithParallel(inputPath, outputPath) {
  console.log(`üóúÔ∏è Compression de ${path.basename(inputPath)}...`);
  
  try {
    // V√©rifier si pigz est disponible
    let cmd;
    try {
      execSync('which pigz', { stdio: 'ignore' });
      // Utiliser pigz pour la compression parall√®le
      cmd = `tar cf - "${inputPath}" | pigz -p ${CONCURRENCY} > "${outputPath}"`;
    } catch {
      // Fallback √† gzip standard
      cmd = `tar czf "${outputPath}" "${inputPath}"`;
    }
    
    execSync(cmd, { stdio: 'inherit' });
    console.log(`‚úÖ Compression termin√©e: ${path.basename(outputPath)}`);
    return true;
  } catch (err) {
    console.error(`‚ùå Erreur lors de la compression:`, err.message);
    return false;
  }
}

/**
 * Transforme un fichier texte en streaming avec une fonction de modification
 * @param {string} inputPath - Chemin du fichier d'entr√©e
 * @param {string} outputPath - Chemin du fichier de sortie
 * @param {Function} transformer - Fonction de transformation (chunk) => transformedChunk
 */
async function transformTextFile(inputPath, outputPath, transformer) {
  console.log(`üîÑ Transformation de ${path.basename(inputPath)}...`);
  
  try {
    const result = await processFileStream(inputPath, outputPath, [transformer], { 
      useRamDisk: true, // Utiliser le RAM disk si disponible
      highWaterMark: 64 * 1024 // 64KB chunks
    });
    
    if (result.success) {
      console.log(`‚úÖ Transformation termin√©e: ${path.basename(outputPath)}`);
      return true;
    } else {
      console.error(`‚ùå Erreur lors de la transformation:`, result.error);
      return false;
    }
  } catch (err) {
    console.error(`‚ùå Erreur lors de la transformation:`, err.message);
    return false;
  }
}

/**
 * Traite un batch de fichiers en parall√®le avec une limite de concurrence
 * @param {Array<Object>} files - Liste des fichiers √† traiter {input, output, transform}
 */
async function processBatchFiles(files) {
  console.log(`üîÑ Traitement de ${files.length} fichiers avec ${CONCURRENCY} workers...`);
  
  try {
    const filesConfig = files.map(file => ({
      input: file.input,
      output: file.output,
      transformers: [file.transform]
    }));
    
    const results = await batchProcessFiles(filesConfig, CONCURRENCY, { 
      useRamDisk: true // Utiliser le RAM disk si disponible
    });
    
    const succeeded = results.filter(r => r.success).length;
    const failed = results.filter(r => !r.success).length;
    
    console.log(`‚úÖ Traitement termin√©: ${succeeded} succ√®s, ${failed} √©checs`);
    return results;
  } catch (err) {
    console.error(`‚ùå Erreur lors du traitement batch:`, err.message);
    return [];
  }
}

/**
 * Affiche les instructions d'utilisation
 */
function showUsage() {
  console.log(`
üöÄ Pipeline Optimis√© - Usage:
----------------------------
Ce script d√©montre un pipeline optimis√© pour le traitement de donn√©es avec:
  - RAM Disk pour les op√©rations temporaires
  - Streaming de fichiers par chunks
  - Gestion intelligente des workers
  - Extraction acc√©l√©r√©e avec libarchive

Commands:
  extract <archive> <destination>  Extrait une archive avec libarchive
  compress <input> <output>        Compresse un fichier/dossier avec compression parall√®le
  transform <input> <output>       Transforme un fichier texte en streaming
  batch                            Ex√©cute un traitement batch de fichiers de d√©monstration
  check                            V√©rifie les d√©pendances et la configuration
  
Exemples:
  node optimized-pipeline.js extract archive.zip ./output
  node optimized-pipeline.js compress ./data data.tar.gz
  node optimized-pipeline.js transform input.txt output.txt
  node optimized-pipeline.js batch
  node optimized-pipeline.js check
`);
}

/**
 * Point d'entr√©e principal
 */
async function main() {
  // V√©rifier les arguments
  const args = process.argv.slice(2);
  if (args.length === 0) {
    showUsage();
    return;
  }
  
  // V√©rifier le RAM Disk et les d√©pendances
  const ramDiskAvailable = checkRamDisk();
  const dependenciesInstalled = checkDependencies();
  
  // Afficher un message si le RAM Disk n'est pas disponible
  if (!ramDiskAvailable) {
    console.log('‚ö†Ô∏è Les performances seront sous-optimales sans RAM Disk');
  }
  
  // Ex√©cuter la commande appropri√©e
  const command = args[0].toLowerCase();
  
  switch (command) {
    case 'extract':
      if (args.length !== 3) {
        console.error('‚ùå Usage: node optimized-pipeline.js extract <archive> <destination>');
        return;
      }
      if (dependenciesInstalled) {
        extractWithLibarchive(args[1], args[2]);
      }
      break;
      
    case 'compress':
      if (args.length !== 3) {
        console.error('‚ùå Usage: node optimized-pipeline.js compress <input> <output>');
        return;
      }
      compressWithParallel(args[1], args[2]);
      break;
      
    case 'transform':
      if (args.length !== 3) {
        console.error('‚ùå Usage: node optimized-pipeline.js transform <input> <output>');
        return;
      }
      await transformTextFile(args[1], args[2], chunk => {
        // Exemple de transformation: convertir en majuscules
        return chunk.toString().toUpperCase();
      });
      break;
      
    case 'batch':
      // Cr√©er des fichiers de d√©monstration si n√©cessaires
      const demoDir = path.join(__dirname, 'demo-data');
      if (!fs.existsSync(demoDir)) {
        fs.mkdirSync(demoDir, { recursive: true });
      }
      
      // Cr√©er des fichiers de test
      for (let i = 1; i <= 5; i++) {
        const content = `Fichier de test ${i}\n`.repeat(1000 * i);
        fs.writeFileSync(path.join(demoDir, `test${i}.txt`), content);
      }
      
      // Pr√©parer les t√¢ches de transformation
      const tasks = Array.from({ length: 5 }, (_, i) => {
        const num = i + 1;
        return {
          input: path.join(demoDir, `test${num}.txt`),
          output: path.join(demoDir, `output${num}.txt`),
          transform: chunk => {
            // Simuler une transformation plus ou moins lourde selon la taille du fichier
            const data = chunk.toString();
            return data.toUpperCase().split('').reverse().join('');
          }
        };
      });
      
      // Ex√©cuter le traitement batch
      await processBatchFiles(tasks);
      break;
      
    case 'check':
      // D√©j√† fait au d√©but
      break;
      
    default:
      console.error(`‚ùå Commande inconnue: ${command}`);
      showUsage();
      break;
  }
}

// Ex√©cuter le script
main().catch(err => {
  console.error('‚ùå Erreur globale:', err);
  process.exit(1);
});